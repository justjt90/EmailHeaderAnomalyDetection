{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkQzXPCXUxme"
   },
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed_spam_ham_phishing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove features that are specific to the old ham/spam data set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hops', 'content-encoding-val', 'received_str_forged', 'str_content-encoding_empty', 'str_from_question', 'str_from_chevron', 'str_to_chevron', 'str_to_empty', 'str_message-ID_dollar', 'str_return-path_bounce', 'str_content-type_texthtml', 'str_precedence_list', 'length_from', 'num_recipients_to', 'num_recipients_cc', 'number_replies', 'x-priority', 'content-length', 'day_of_week', 'date_comp_date_received', 'span_time', 'conseq_num_received_is_one', 'conseq_received_good', 'conseq_received_bad', 'conseq_received_date', 'email_match_from_reply-to', 'domain_match_message-id_from', 'domain_match_from_return-path', 'domain_match_message-id_return-path', 'domain_match_message-id_sender', 'domain_match_message-id_reply-to', 'domain_match_return-path_reply-to', 'domain_match_reply-to_to', 'domain_match_to_in-reply-to', 'domain_match_errors-to_message-id', 'domain_match_errors-to_from', 'domain_match_errors-to_sender', 'domain_match_errors-to_reply-to', 'domain_match_sender_from', 'domain_match_references_reply-to', 'domain_match_references_in-reply-to', 'domain_match_references_to', 'domain_match_from_reply-to', 'domain_match_to_from', 'domain_match_to_message-id', 'domain_match_to_received', 'label']\n"
     ]
    }
   ],
   "source": [
    "remove_list = ['time_zone', 'lines', 'domain_val_message-id']\n",
    "\n",
    "for val in features_list:\n",
    "    if 'missing' in val:\n",
    "        remove_list.append(val)\n",
    "        \n",
    "final_features = []\n",
    "for val in features_list:\n",
    "    if val not in remove_list:\n",
    "        final_features.append(val)\n",
    "        \n",
    "print(final_features)\n",
    "\n",
    "df = df[final_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove spam emails, only consider ham and phishing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75423, 47)\n",
      "(1288, 47)\n"
     ]
    }
   ],
   "source": [
    "df_phish = df[df['label'] == 2]\n",
    "df = df[df['label'] != 2]\n",
    "print(df.shape)\n",
    "print(df_phish.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Y_phish = df_phish['label']\n",
    "df_X_phish = df_phish.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288,)\n",
      "(1288, 46)\n"
     ]
    }
   ],
   "source": [
    "print(df_Y_phish.shape)\n",
    "print(df_X_phish.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a dataset of half ham emails and half phishing emails:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25220, 47)\n"
     ]
    }
   ],
   "source": [
    "df_ham = df[df['label'] == 0]\n",
    "print(df_ham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288, 47)\n"
     ]
    }
   ],
   "source": [
    "df_ham_subset = df_ham.sample(n = 1288, replace=False)\n",
    "print(df_ham_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1288,)\n",
      "(1288, 46)\n"
     ]
    }
   ],
   "source": [
    "df_ham_Y = df_ham_subset['label']\n",
    "df_ham_X = df_ham_subset.drop(columns=['label'])\n",
    "print(df_ham_Y.shape)\n",
    "print(df_ham_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2576, 46)\n",
      "(2576,)\n"
     ]
    }
   ],
   "source": [
    "df_combined_X = df_ham_X.append(df_X_phish, ignore_index=True)\n",
    "df_combined_Y = df_ham_Y.append(df_Y_phish, ignore_index=True)\n",
    "print(df_combined_X.shape)\n",
    "print(df_combined_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(df_combined_X.index)\n",
    "df_combined_X = df_combined_X.reindex(idx)\n",
    "df_combined_Y = df_combined_Y.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hops</th>\n",
       "      <th>content-encoding-val</th>\n",
       "      <th>received_str_forged</th>\n",
       "      <th>str_content-encoding_empty</th>\n",
       "      <th>str_from_question</th>\n",
       "      <th>str_from_chevron</th>\n",
       "      <th>str_to_chevron</th>\n",
       "      <th>str_to_empty</th>\n",
       "      <th>str_message-ID_dollar</th>\n",
       "      <th>str_return-path_bounce</th>\n",
       "      <th>...</th>\n",
       "      <th>domain_match_errors-to_sender</th>\n",
       "      <th>domain_match_errors-to_reply-to</th>\n",
       "      <th>domain_match_sender_from</th>\n",
       "      <th>domain_match_references_reply-to</th>\n",
       "      <th>domain_match_references_in-reply-to</th>\n",
       "      <th>domain_match_references_to</th>\n",
       "      <th>domain_match_from_reply-to</th>\n",
       "      <th>domain_match_to_from</th>\n",
       "      <th>domain_match_to_message-id</th>\n",
       "      <th>domain_match_to_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2202</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hops  content-encoding-val  received_str_forged  \\\n",
       "2202     0                     1                    0   \n",
       "499      1                     0                    0   \n",
       "280      2                     1                    0   \n",
       "1316     1                     1                    0   \n",
       "2033     1                     1                    0   \n",
       "\n",
       "      str_content-encoding_empty  str_from_question  str_from_chevron  \\\n",
       "2202                         0.0                0.0               0.0   \n",
       "499                          0.0                0.0               1.0   \n",
       "280                          1.0                0.0               1.0   \n",
       "1316                         1.0                0.0               1.0   \n",
       "2033                         0.0                0.0               1.0   \n",
       "\n",
       "      str_to_chevron  str_to_empty  str_message-ID_dollar  \\\n",
       "2202             0.0           0.0                    0.0   \n",
       "499              0.0           0.0                    0.0   \n",
       "280              1.0           0.0                    0.0   \n",
       "1316             0.0           1.0                    0.0   \n",
       "2033             0.0           0.0                    0.0   \n",
       "\n",
       "      str_return-path_bounce  ...  domain_match_errors-to_sender  \\\n",
       "2202                     0.0  ...                              0   \n",
       "499                      1.0  ...                              0   \n",
       "280                      1.0  ...                              1   \n",
       "1316                     0.0  ...                              0   \n",
       "2033                     0.0  ...                              0   \n",
       "\n",
       "      domain_match_errors-to_reply-to  domain_match_sender_from  \\\n",
       "2202                                0                         0   \n",
       "499                                 0                         0   \n",
       "280                                 0                         0   \n",
       "1316                                0                         0   \n",
       "2033                                0                         0   \n",
       "\n",
       "      domain_match_references_reply-to  domain_match_references_in-reply-to  \\\n",
       "2202                                 0                                    0   \n",
       "499                                  0                                    0   \n",
       "280                                  0                                    0   \n",
       "1316                                 0                                    0   \n",
       "2033                                 0                                    0   \n",
       "\n",
       "      domain_match_references_to  domain_match_from_reply-to  \\\n",
       "2202                           0                           0   \n",
       "499                            0                           0   \n",
       "280                            1                           1   \n",
       "1316                           0                           0   \n",
       "2033                           0                           0   \n",
       "\n",
       "      domain_match_to_from  domain_match_to_message-id  \\\n",
       "2202                     0                           0   \n",
       "499                      0                           0   \n",
       "280                      0                           0   \n",
       "1316                     0                           0   \n",
       "2033                     0                           0   \n",
       "\n",
       "      domain_match_to_received  \n",
       "2202                         0  \n",
       "499                          0  \n",
       "280                          0  \n",
       "1316                         0  \n",
       "2033                         0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2202    1.0\n",
       "499     0.0\n",
       "280     0.0\n",
       "1316    1.0\n",
       "2033    1.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_Y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rffvHbuzGO8c"
   },
   "source": [
    "# **Testing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA9ns0c3ovCG"
   },
   "source": [
    "**Supervised anomaly detection (classification problem, using PCA):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "fk0rbKYdP5QA",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  LogisticRegression \n",
      "\n",
      "fit_time Average: 0.0344 +- 0.0030\n",
      "score_time Average: 0.0086 +- 0.0005\n",
      "test_accuracy Average: 0.9984 +- 0.0019\n",
      "train_accuracy Average: 0.9996 +- 0.0001\n",
      "test_f1 Average: 0.9985 +- 0.0019\n",
      "train_f1 Average: 0.9996 +- 0.0001\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9969 +- 0.0038\n",
      "train_precision Average: 0.9992 +- 0.0003\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  SVC \n",
      "\n",
      "fit_time Average: 0.0435 +- 0.0018\n",
      "score_time Average: 0.0180 +- 0.0013\n",
      "test_accuracy Average: 0.9996 +- 0.0012\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9996 +- 0.0012\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9992 +- 0.0023\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  GradientBoostingClassifier \n",
      "\n",
      "fit_time Average: 0.5845 +- 0.0066\n",
      "score_time Average: 0.0099 +- 0.0003\n",
      "test_accuracy Average: 0.9996 +- 0.0012\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9996 +- 0.0012\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9992 +- 0.0023\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  MLPClassifier \n",
      "\n",
      "fit_time Average: 0.8082 +- 0.0372\n",
      "score_time Average: 0.0101 +- 0.0003\n",
      "test_accuracy Average: 0.9992 +- 0.0016\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9992 +- 0.0016\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9985 +- 0.0031\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  GaussianNB \n",
      "\n",
      "fit_time Average: 0.0200 +- 0.0004\n",
      "score_time Average: 0.0082 +- 0.0004\n",
      "test_accuracy Average: 0.9177 +- 0.0169\n",
      "train_accuracy Average: 0.9206 +- 0.0054\n",
      "test_f1 Average: 0.9161 +- 0.0177\n",
      "train_f1 Average: 0.9197 +- 0.0054\n",
      "test_recall Average: 0.8999 +- 0.0260\n",
      "train_recall Average: 0.9086 +- 0.0057\n",
      "test_precision Average: 0.9335 +- 0.0192\n",
      "train_precision Average: 0.9310 +- 0.0060\n",
      "test_roc_auc Average: 0.9734 +- 0.0099\n",
      "train_roc_auc Average: 0.9748 +- 0.0012\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  BernoulliNB \n",
      "\n",
      "fit_time Average: 0.0206 +- 0.0006\n",
      "score_time Average: 0.0082 +- 0.0004\n",
      "test_accuracy Average: 0.9437 +- 0.0178\n",
      "train_accuracy Average: 0.9437 +- 0.0088\n",
      "test_f1 Average: 0.9433 +- 0.0180\n",
      "train_f1 Average: 0.9433 +- 0.0089\n",
      "test_recall Average: 0.9379 +- 0.0260\n",
      "train_recall Average: 0.9372 +- 0.0145\n",
      "test_precision Average: 0.9494 +- 0.0226\n",
      "train_precision Average: 0.9498 +- 0.0125\n",
      "test_roc_auc Average: 0.9879 +- 0.0049\n",
      "train_roc_auc Average: 0.9871 +- 0.0019\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  RandomForestClassifier \n",
      "\n",
      "fit_time Average: 0.6212 +- 0.0125\n",
      "score_time Average: 0.0360 +- 0.0014\n",
      "test_accuracy Average: 1.0000 +- 0.0000\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 1.0000 +- 0.0000\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 1.0000 +- 0.0000\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  DecisionTreeClassifier \n",
      "\n",
      "fit_time Average: 0.0443 +- 0.0031\n",
      "score_time Average: 0.0077 +- 0.0007\n",
      "test_accuracy Average: 0.9953 +- 0.0038\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9954 +- 0.0038\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9908 +- 0.0074\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 0.9953 +- 0.0038\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  KNeighborsClassifier \n",
      "\n",
      "fit_time Average: 0.0357 +- 0.0010\n",
      "score_time Average: 0.0270 +- 0.0013\n",
      "test_accuracy Average: 0.9981 +- 0.0026\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9981 +- 0.0026\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9962 +- 0.0051\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 0.9981 +- 0.0026\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "\n",
      "---------------------------------------------------\n",
      "Current classifier:  AdaBoostClassifier \n",
      "\n",
      "fit_time Average: 1.6508 +- 0.0240\n",
      "score_time Average: 0.0672 +- 0.0028\n",
      "test_accuracy Average: 0.9996 +- 0.0012\n",
      "train_accuracy Average: 1.0000 +- 0.0000\n",
      "test_f1 Average: 0.9996 +- 0.0012\n",
      "train_f1 Average: 1.0000 +- 0.0000\n",
      "test_recall Average: 1.0000 +- 0.0000\n",
      "train_recall Average: 1.0000 +- 0.0000\n",
      "test_precision Average: 0.9992 +- 0.0023\n",
      "train_precision Average: 1.0000 +- 0.0000\n",
      "test_roc_auc Average: 1.0000 +- 0.0000\n",
      "train_roc_auc Average: 1.0000 +- 0.0000\n",
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "lw = 2\n",
    "graph = None\n",
    "classifiers = [LogisticRegression(solver='lbfgs', fit_intercept=False, tol=0.0001, penalty='l2', C=1, max_iter=500), \n",
    "               SVC(C=10, kernel='rbf', tol=0.01), \n",
    "               GradientBoostingClassifier(learning_rate=0.4, n_estimators=200, max_features='log2'),\n",
    "               MLPClassifier(hidden_layer_sizes=(40,40), activation='relu', learning_rate='constant', alpha=0.001, solver='adam'), \n",
    "               GaussianNB(), \n",
    "               BernoulliNB(), \n",
    "               RandomForestClassifier(n_estimators=150, criterion='gini', min_samples_split=3, min_samples_leaf=1, max_features='log2'), \n",
    "               DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=1, ccp_alpha=0,), \n",
    "               KNeighborsClassifier(algorithm='kd_tree', weights='uniform', p=1, n_neighbors=1, leaf_size=15),\n",
    "               AdaBoostClassifier(n_estimators=200, learning_rate=0.95, algorithm='SAMME.R')]\n",
    "\n",
    "for c in classifiers:\n",
    "    \n",
    "    pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                    (\"reduce_dims\", PCA(n_components=40)),\n",
    "                    (c.__class__.__name__, c)\n",
    "                    ])\n",
    "\n",
    "    print(\"\\n---------------------------------------------------\")\n",
    "    print(\"Current classifier: \", c.__class__.__name__, \"\\n\")\n",
    "\n",
    "    scoring = ['accuracy', 'f1', 'recall', 'precision', 'roc_auc']\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    scores = cross_validate(pipe, df_combined_X, df_combined_Y, scoring=scoring, cv=cv, return_train_score=True)\n",
    "    \n",
    "    for key, val in scores.items():\n",
    "        print(key, \"Average:\", \"{:.4f}\".format(np.average(val)), \"+-\", \"{:.4f}\".format(np.std(val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for c in classifiers:\n",
    "    \n",
    "    pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                    (\"reduce_dims\", PCA(n_components=40)),\n",
    "                    (c.__class__.__name__, c)\n",
    "                    ])\n",
    "\n",
    "    print(\"\\n---------------------------------------------------\")\n",
    "    print(\"Current classifier: \", c.__class__.__name__, \"\\n\")\n",
    "    \n",
    "    scores = {'accuracy': [], 'f1': [], 'recall': [], 'precision': []}\n",
    "    \n",
    "\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(df_X, df_Y):\n",
    "        X_train, X_test = df_X.iloc[train_index], df_X.iloc[test_index]\n",
    "        y_train, y_test = df_Y.iloc[train_index], df_Y.iloc[test_index]\n",
    "    \n",
    "        c.fit(X_train, y_train)\n",
    "        predictions = c.predict(df_X_phish)\n",
    "        \n",
    "        scores['accuracy'].append(accuracy_score(df_Y_phish, predictions))\n",
    "        scores['f1'].append(f1_score(df_Y_phish, predictions))\n",
    "        scores['recall'].append(recall_score(df_Y_phish, predictions))\n",
    "        scores['precision'].append(precision_score(df_Y_phish, predictions))\n",
    "\n",
    "    for key, val in scores.items():\n",
    "        print(key, \"Average:\", \"{:.4f}\".format(np.average(val)), \"+-\", \"{:.4f}\".format(np.std(val)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YBgzEfzRSqa"
   },
   "source": [
    "**Supervised Stacked Classifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R2ikJyxFRU_U"
   },
   "outputs": [],
   "source": [
    "base_learners = [('mlp', MLPClassifier(hidden_layer_sizes=(40,40), activation='relu', learning_rate='constant', alpha=0.001, solver='adam')), \n",
    "                 ('knn', RandomForestClassifier(n_estimators=150, criterion='gini', min_samples_split=3, min_samples_leaf=1, max_features='log2'))]\n",
    "meta_classifier = LogisticRegression()\n",
    "\n",
    "stacked_classifier = StackingClassifier(estimators=base_learners, \n",
    "                                        final_estimator=meta_classifier)\n",
    "\n",
    "pipe = Pipeline([(\"scale\", StandardScaler()),\n",
    "                (\"reduce_dims\", PCA(n_components=40)),\n",
    "                ('stacked', stacked_classifier)\n",
    "                ])\n",
    "\n",
    "scoring = ['accuracy', 'f1', 'recall', 'precision', 'roc_auc']\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "scores = cross_validate(pipe, df_X, df_Y, scoring=scoring, cv=cv, return_train_score=True, verbose=10, n_jobs=-1)\n",
    "\n",
    "for key, val in scores.items():\n",
    "    print(key, \"Average:\", \"{:.4f}\".format(np.average(val)), \"+-\", \"{:.4f}\".format(np.std(val)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "sCMEqns8jY-1",
    "F5A997Ekjh0E",
    "KvWjb8GwOM-y",
    "rJJ4WHSBFTWc",
    "nqHSyA4SyJ7K",
    "xhkNe2ql-cFP",
    "fMwsPWxpi2cG",
    "-_nEjwFOjUDI",
    "MyekmTK3q5TC",
    "RkQzXPCXUxme",
    "P1zXPP6trxSN",
    "iGZ561te2ONO",
    "rffvHbuzGO8c"
   ],
   "name": "Capstone Project - Email Headers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
